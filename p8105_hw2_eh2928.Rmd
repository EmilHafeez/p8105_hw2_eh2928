---
title: "Data Science 1, Homework 2"
author: "Emil Hafeez (eh2928)"
date: "9/24/2020"
output: github_document
---
## Read in the libraries
```{r setup, include = FALSE,warning = FALSE, message = FALSE}
library(tidyverse)
library(readxl)
```

# Problem One
Here, we read in the data from the Mr. Trashwheel sheet of an Excel document, to create a dataframe. Mr. Trash Wheel is great! I met him when I lived in Baltimore in 2016 to 2018. I follow him on Instagram. 

We specify the data in the sheet, as well as clean the variable names, drop the rows without dumpster-specific data (which appear to be subtotals in the original sheet), and then round a variable to the nearest integer and store that variable respectively as an integer. That's it! In 10 lines! 
```{r trashwheel df and cleaning}
trashwheel_df = 
    read_xlsx(
      path =  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "Mr. Trash Wheel",
      range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
	mutate(
		sports_balls = round(sports_balls),
		sports_balls = as.integer(sports_balls)
      )
```
Now, we implement a similar cleaning process as above, though instead for two years of precipitation data. We also omit rows without precipitation data, and also add a variable for the year.
```{r precipitation_2017_df}
precipitation_2017_df = 
    read_xlsx(
      path =  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "2017 Precipitation", 
		  skip = 1) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
	mutate(year = 2017) %>% 
  relocate(year, before = month)
```

```{r precipitation_2018_df}
precipitation_2018_df = 
    read_xlsx(
      path =  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "2018 Precipitation", 
		  skip = 1) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
	mutate(year = 2018) %>% 
  relocate(year, before = month)
```
We now combine the 2017 and 2018 datasets, and convert the month into a character variable.
The month-conversion is accomplished with the help of a 'helper' tibble. I vary the order of commands from the demonstrated code, to cluster the related actions closer (and just to experiment and make sure it also works that way).
```{r combine precipitation dataframes and change the month var}
precipitation_combined_df = 
	bind_rows(precipitation_2018_df, precipitation_2017_df)

month_helper_df = 
	tibble(
		month = 1:12,
		month_name = month.name
	)

precipitation_combined_df =
	left_join(precipitation_combined_df, month_helper_df, by = "month")
```
These data relate information on the date, type, volume, and counts of various trash collected by Baltimore's beloved Mr. Trash Wheel. Additional data sheets include monthly precipitation data, and other Trash Wheel's data (the latter of which  we do not utilize). Note that in the Mr. Trash Wheel dataframe, there are `r nrow(trashwheel_df)` rows, and `r ncol(trashwheel_df)` columns. Meanwhile,  the precipitation dataset representing the combination of 2017 and 2018 data has `r nrow(precipitation_combined_df)` rows and `r ncol(precipitation_combined_df)` columns. There was `r precipitation_combined_df %>% filter(year == 2018) %>%  pull(total) %>% sum()` inches of precipitation in 2018! 

Mr. Trash Wheel, amazingly, prevented `r trashwheel_df %>% filter(year == 2017) %>% pull(weight_tons) %>% sum()` tons of trash from entering the Baltimore Inner Harbor in 2017 and `r trashwheel_df %>% filter(year == 2018) %>% pull(weight_tons) %>% sum()` tons in 2018. The median number of sports balls in a 2017 dumpster was `r trashwheel_df %>% filter(year == 2017) %>% pull(sports_balls) %>% median()`.

# Problem Two
Here, we focus on NYC Transit data relating to entrances and exits for each subway station in NYC. 

Read and clean the data; retain line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance. Convert the entry variable from character (YES vs NO) to a logical variable.
```{r NYC Transit cleanings, warning = FALSE, message = FALSE, results = FALSE}
transit_df =
  read_csv(
      "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:vending, ada, -exit_only) %>% 
  mutate(entry = recode(entry, YES = TRUE, NO = FALSE)) %>% 
  mutate(vending = recode(vending, YES = TRUE, NO = FALSE)) 
```
These data relate information on the NYC subway; it includes variables for lines, routes, and station characteristics (including ADA accessibility and location). It has `r nrow(transit_df)` rows, and `r ncol(transit_df)` columns; the cleaned data are a subset of the raw data. We've selected the subset of raw data relevant to our task, as well as cleaned the variable names, and converted two variables to a logical variable (I took the liberty with "entry"). However, these data are not tidy: the data could be represented more tidily by condensing all of the route variables into one, which would also make it feasible to represent distinct line and station name combinations with fewer rows.

Note that there are `r distinct(transit_df, line, station_name) %>% count()` distinct stations (by line and station_name combination). Only `r filter(transit_df, ada == TRUE) %>% distinct(line, station_name) %>% count()` of the `r distinct(transit_df, line, station_name) %>% nrow()` distinct stations are ADA compliant. Something that may also bother you is that only `r filter(transit_df, vending == FALSE) %>% filter(entry == TRUE) %>% count()` subway entrances without vending allow entry.

Now, reformat data so that route number and route name are distinct variables. 
```{r reformat and then calculate some specifics}
transit_tidy_df =
  transit_df %>% 
  mutate(route8 = (as.character(route8))) %>% 
  mutate(route9 = (as.character(route8))) %>% 
  mutate(route10 = (as.character(route10))) %>% 
  mutate(route11 = (as.character(route11))) %>% 
  pivot_longer(
    route1:route11,
    names_to = "routes_number_served",
    values_to = "routes_name_served"
    ) %>% 
  mutate(routes_number_served = str_remove_all(routes_number_served, "route"))

################################################################################################################################################################ARE THESE MISSING DATA A MISTAKE? SHOULD I REMOVE THEM?
```
There are `r filter(transit_tidy_df, str_detect(routes_name_served, "A")) %>% distinct(line, station_name) %>% count()` stations that are distinct by their line and station name which serve the A train. Of these, only `r filter(transit_tidy_df, ada == TRUE) %>% distinct(line, station_name) %>% count()` are ADA compliant.

# Problem Three
First, clean the data in the pols-month CSV. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name. Then, create a president variable taking values gop and dem. Then, remove prez_dem and prez_gop; and remove the day variable.
```{r clean pols-month}
pols_month_df =
  read_csv(
      "./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(month = as.numeric(month)) 
pols_month_df =
  left_join(pols_month_df, month_helper_df, by = "month") %>% 
  relocate(month_name, before = month) %>% 
  select(-month) %>% 
  mutate(
      prez_dem = recode(prez_dem, `1` = "dem", `0` = "gop")
      ) %>% 
  rename(president = prez_dem) %>% 
  rename(month = month_name) %>% 
  select(-prez_gop, day)
```
Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.
```{r snp.csv cleanings, warning = FALSE, message = FALSE}
snp_df =
  read_csv(
      "./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year")) %>% 
  mutate(month = as.numeric(month)) 
snp_df =
  left_join(snp_df, month_helper_df, by = "month") %>% 
  select(-month, -day) %>% 
  rename(month = month_name) %>% 
  relocate(month, after = year)
##why isn't the location working well?####################################################################################################
```
Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values. 
```{r tidy the unemployment data, warning = FALSE, message = FALSE}
unemployment_df =
  read_csv(
      "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_percentage"
  ) %>% 
  mutate(
    month = recode(month, `jan` = "1", `feb` = "2", `mar` = "3", `apr` = "4", 
                   `may` = "5", `jun` = "6", `jul` = "7", `aug` = "8", 
                   `sep` = "9", `oct` = "10", `nov` = "11", `dec` = "12")
        ) %>% 
  mutate(month = as.numeric(month))

unemployment_df =
  left_join(unemployment_df, month_helper_df, by = "month") %>% 
  relocate(month_name, before = month) %>% 
  select(-month) %>% 
  rename(month = month_name)
```
Join the datasets by merging snp into pols, and merging unemployment into the result.
```{r joining snp, pols, and unemployment}
fivethirtyeight_df = 
  left_join(pols_month_df, snp_df, by = c("month" = "month", "year" = "year")) %>% 
    mutate(year = as.numeric(year)) 
################################################################################CAN YOU POLISH THE LOCATION OF THE MUTATE LINE TO SOMEWHERE MORE FLUID?
fivethirtyeight_df = 
  left_join(fivethirtyeight_df, unemployment_df, by = c("month" = "month", "year" = "year"))
```
Write a short paragraph about these datasets. Explain briefly what each dataset contained, and describe the resulting dataset (e.g. give the dimension, range of years, and names of key variables).

These datasets are sourced from fivethirtyeight.com, founded by data-driven sports-analyst turned economist, political pundit, and still-sports-analyst Nate Silver. 

Each dataset is organized by month and year. The "pols-month" dataset contains 10 variables that relate the number of Democratic and Republican politicians in power (seated in  USA governorships, the House of Representatives, the Senate, and the presidency), and it contains `r nrow(pols_month_df)` rows, and `r ncol(pols_month_df)` columns. The "snp" dataset shows the S&P index at closing, with `r nrow(snp_df)` rows, and `r ncol(snp_df)` columns; the "unemployment" dataset shows the percentage of unemployment in the USA, with `r nrow(unemployment_df)` rows, and `r ncol(unemployment_df)` columns. 

Each dataset is organized by month and year. The "pols-month" dataset contains 10 variables that relate the number of Democratic and Republican politicians in power (seated in  USA governorships, the House of Representatives, the Senate, and the presidency), and it contains `r nrow(pols_month_df)` rows, and `r ncol(pols_month_df)` columns. The "snp" dataset shows the S&P index at closing, with `r nrow(snp_df)` rows, and `r ncol(snp_df)` columns; the "unemployment" dataset shows the percentage of unemployment in the USA, with `r nrow(unemployment_df)` rows, and `r ncol(unemployment_df)` columns. 

After combining these by the month and year, the resultant "fivethirtyeight" dataset has `r nrow(fivethirtyeight_df)` rows, and `r ncol(fivethirtyeight_df)` columns, covering `r range(pull(fivethirtyeight_df, year))` years. It has month and year variables, as well as the aforementioned national politicians, plus we have joined on the S&P value every month, and the unemployment rate (as a percentage). 