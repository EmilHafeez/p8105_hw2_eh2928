Data Science 1, Homework 2
================
Emil Hafeez (eh2928)
9/24/2020

Read in the libraries, firstly\!

``` r
library(tidyverse)
```

    ## ── Attaching packages ────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ───────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

# Problem One

Here, we read in the data from the Mr. Trash Wheel sheet of an Excel
document, to create a dataframe. Mr. Trash Wheel is great\! I met him
when I lived in Baltimore in 2016 to 2018.

We specify the data in the sheet, as well as clean the variable names,
drop the rows without dumpster-specific data (which appear to be
subtotals in the original sheet), and then round a variable to the
nearest integer and store that variable respectively as an integer.
That’s it\! In 10 lines\!

``` r
trashwheel_df = 
    read_xlsx(
      path =  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "Mr. Trash Wheel",
      range = cell_cols("A:N")) %>% 
    janitor::clean_names() %>% 
    drop_na(dumpster) %>% 
    mutate(
        sports_balls = round(sports_balls),
        sports_balls = as.integer(sports_balls)
      )
```

Now, we implement a similar cleaning process as above, though instead
for two years of precipitation data. Different sheets from the same
file. We also omit rows without precipitation data (which removes the
last ‘totalizing’ row from the Excel), and also add a variable for the
year (and relocate it).

``` r
precipitation_2017_df = 
    read_xlsx(
      path =  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "2017 Precipitation", 
          skip = 1) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2017) %>% 
  relocate(year, before = month)
```

``` r
precipitation_2018_df = 
    read_xlsx(
      path =  "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
      sheet = "2018 Precipitation", 
          skip = 1) %>% 
    janitor::clean_names() %>% 
    drop_na(month) %>% 
    mutate(year = 2018) %>% 
  relocate(year, before = month)
```

We now combine the 2017 and 2018 datasets, and convert the month into a
character variable. The month-conversion is accomplished with the help
of a ‘helper’ tibble. I vary the order of commands from the demonstrated
code, to cluster the related actions closer (and just to experiment and
make sure it also works that way).

``` r
precipitation_combined_df = 
    bind_rows(precipitation_2018_df, precipitation_2017_df)

month_helper_df = 
    tibble(
        month = 1:12,
        month_name = month.name
    )

precipitation_combined_df =
    left_join(precipitation_combined_df, month_helper_df, by = "month")
```

These data relate information on the date, type, volume, and counts of
various trash collected by Baltimore’s beloved Mr. Trash Wheel.
Additional data sheets include monthly precipitation data, and other
Trash Wheel’s data (the latter of which we do not utilize). Note that in
the Mr. Trash Wheel dataframe, there are 344 rows, and 14 columns.
Meanwhile, the precipitation dataset representing the combination of
2017 and 2018 data has 24 rows and 4 columns. There was 70.33 inches of
precipitation in 2018\!

Mr. Trash Wheel, amazingly, prevented 174.84 tons of trash from entering
the Baltimore Inner Harbor in 2017 and 310.39 tons in 2018. The median
number of sports balls in a 2017 dumpster was 8.

# Problem Two

Here, we focus on NYC Transit data relating to entrances and exits for
each subway station in NYC.

Read and clean the data; retain line, station, name, station latitude /
longitude, routes served, entry, vending, entrance type, and ADA
compliance. Convert the entry variable from character (YES vs NO) to a
logical variable.

``` r
transit_df =
  read_csv(
      "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line:vending, ada, -exit_only) %>% 
  mutate(entry = recode(entry, YES = TRUE, NO = FALSE)) %>% 
  mutate(vending = recode(vending, YES = TRUE, NO = FALSE)) 
```

These data relate information on the NYC subway; it includes variables
for lines, routes, and station characteristics (including ADA
accessibility and location). It has 1868 rows, and 19 columns; the
cleaned data are a subset of the raw data. We’ve selected the subset of
raw data relevant to our task, as well as cleaned the variable names,
and converted two variables to a logical variable (I took the liberty
with “entry”).

These data are not tidy: the data could be represented more tidily by
condensing all of the route variables into one column. Additionally,
many distinct line and station name combinations are duplicated across
rows because of the ‘route’ variable – if one would like each distinct
line- station combination to have a duplicated row for every route it
serves (rather than compressing multiple routes into one cell), it is
possible to remove the duplicates rows with just empty route cells.

Note that there are 465 distinct stations (by line and station\_name
combination). Only 84 of the 465 distinct stations are ADA compliant.
Something that may (should?) also bother you is that only 69 subway
entrances without vending allow entry.

Next, we reformat data so that route number and route name are distinct
variables. We first specify a dataframe to hold the tidied information,
and make the different route columns into the same datatype, and then
pivot them to a longer format. Lastly, we remove the phrase “route” from
each of the cells in the new column, and then remove rows where the
route data is missing.

``` r
transit_tidy_df =
  transit_df %>% 
  mutate(route8 = (as.character(route8))) %>% 
  mutate(route9 = (as.character(route8))) %>% 
  mutate(route10 = (as.character(route10))) %>% 
  mutate(route11 = (as.character(route11))) %>% 
  pivot_longer(
    route1:route11,
    names_to = "routes_number_served",
    values_to = "routes_name_served"
    ) %>% 
  mutate(routes_number_served = str_remove_all(routes_number_served, "route")) %>% 
  na.omit()
```

There are 60 stations that are distinct by their line and station name
which serve the A train. Of these, only 84 are ADA compliant.

# Problem Three

First, clean the data in the pols-month CSV. Use separate() to break up
the variable “mon” into integer variables year, month, and day; replace
month number with month name. Then, create a “president” variable taking
values “gop” and “dem”. Then, remove “prez\_dem” and “prez\_gop”; and
remove the “day” variable.

``` r
pols_month_df =
  read_csv(
      "./data/fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month", "day")) %>% 
  mutate(month = as.numeric(month)) 
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
pols_month_df =
  left_join(pols_month_df, month_helper_df, by = "month") %>% 
  relocate(month_name, before = month) %>% 
  select(-month) %>% 
  mutate(
      president = case_when( #Per a discussion board conversation, this function is recommended here
        prez_dem == 1 ~ "dem",
        prez_dem == 0 ~ "gop")
      ) %>% 
  rename(month = month_name) %>%
  select(-prez_gop, -prez_dem, -day)
```

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp_df =
  read_csv(
      "./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year")) %>% 
  mutate(month = as.numeric(month)) 
snp_df =
  left_join(snp_df, month_helper_df, by = "month") %>% 
  select(-month, -day) %>% 
  rename(month = month_name) %>% 
  relocate(year, month)
```

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment_df = 
  read_csv(
      "./data/fivethirtyeight_datasets/unemployment.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment_percentage"
  ) %>% 
  mutate(
    month = recode(month, `jan` = "1", `feb` = "2", `mar` = "3", `apr` = "4", 
                   `may` = "5", `jun` = "6", `jul` = "7", `aug` = "8", 
                   `sep` = "9", `oct` = "10", `nov` = "11", `dec` = "12")
        ) %>% 
  mutate(month = as.numeric(month))
unemployment_df =
  left_join(unemployment_df, month_helper_df, by = "month") %>% 
  relocate(month_name, before = month) %>% 
  select(-month) %>% 
  rename(month = month_name)
# Same result could be obtained using another variable in the month helper tibble with the abbreviations in the mutate, but I like the specificity here of not adjusting that tibble. Perhaps in the future I will always make that tibble with the abbreviations initially?
```

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
fivethirtyeight_df = 
  left_join(pols_month_df, snp_df, by = c("month" = "month", "year" = "year")) %>% 
    mutate(year = as.numeric(year)) 
fivethirtyeight_df = 
  left_join(fivethirtyeight_df, unemployment_df, by = c("month" = "month", "year" = "year"))
```

Short write-up:

These datasets are sourced from fivethirtyeight.com, founded by
data-driven sports-analyst turned economist, political pundit, and
still-sports-analyst Nate Silver.

Each dataset is organized by month and year. The “pols-month” dataset
contains 10 variables that relate the number of Democratic and
Republican politicians in power (seated in USA governorships, the House
of Representatives, the Senate, and the presidency), and it contains 822
rows, and 9 columns. The “snp” dataset shows the S\&P index at closing,
with 787 rows, and 3 columns; the “unemployment” dataset shows the
percentage of unemployment in the USA, with 816 rows, and 3 columns.

Each dataset contains month and year. The “pols-month” dataset contains
10 variables that relate the number of Democratic and Republican
politicians in power (seated in USA governorships, the House of
Representatives, the Senate, and the presidency), and it contains 822
rows, and 9 columns. The “snp” dataset shows the S\&P index at closing,
with 787 rows, and 3 columns; the “unemployment” dataset shows the
percentage of unemployment in the USA, with 816 rows, and 3 columns.

After combining these by the month and year, the resultant
“fivethirtyeight” dataset has 822 rows, and 11 columns, covering 1947,
2015 years. It has month and year variables, as well as the
aforementioned national politicians, plus we have joined on the S\&P
value every month, and the unemployment rate (as a percentage).
